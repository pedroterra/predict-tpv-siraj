{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "import lstm, time #helper libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def plot_results_multiple(predicted_data, true_data, prediction_len):\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(true_data, label='True Data')\n",
    "    #print ('yo')\n",
    "    #Pad the list of predictions to shift it in the graph to it's correct start\n",
    "    for i, data in enumerate(predicted_data):\n",
    "        padding = [None for p in range(i * prediction_len)]\n",
    "        plt.plot(padding + data, label='Prediction')\n",
    "        plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def load_data(filename, seq_len, normalise_window):\n",
    "    f = open(filename, 'r').read()\n",
    "    data = f.split('\\n')\n",
    "\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(len(data) - sequence_length):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "        #print(result)\n",
    "\n",
    "    if normalise_window:\n",
    "        result = normalise_windows2(result)\n",
    "\n",
    "    result = np.array(result)\n",
    "\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-1]\n",
    "    y_train = train[:, -1]\n",
    "    x_test = result[int(row):, :-1]\n",
    "    y_test = result[int(row):, -1]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "# def normalise_windows(window_data):\n",
    "#     normalised_data = []\n",
    "#     for window in window_data:\n",
    "#         normalised_window = [((float(p) / (float(window[0]))) - 1) for p in window]\n",
    "#         normalised_data.append(normalised_window)\n",
    "#     return normalised_data\n",
    "\n",
    "def normalise_windows2(window_data):\n",
    "    normalised_data = []\n",
    "    for window in window_data:\n",
    "        normalised_window = [((float(p) / (float(max(window)))) - 1) for p in window]\n",
    "        normalised_data.append(normalised_window)\n",
    "    return normalised_data\n",
    "\n",
    "def predict_sequences_multiple(model, data, window_size, prediction_len):\n",
    "    #Predict sequence of 50 steps before shifting prediction run forward by 50 steps\n",
    "    prediction_seqs = []\n",
    "    for i in range(int(len(data)/prediction_len)):\n",
    "        curr_frame = data[i*prediction_len]\n",
    "        predicted = []\n",
    "        for j in range(prediction_len):\n",
    "            predicted.append(model.predict(curr_frame[newaxis,:,:])[0,0])\n",
    "            curr_frame = curr_frame[1:]\n",
    "            curr_frame = np.insert(curr_frame, [window_size-1], predicted[-1], axis=0)\n",
    "        prediction_seqs.append(predicted)\n",
    "    return prediction_seqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1 Load Data\n",
    "#X_train, y_train, X_test, y_test = lstm.load_data('sp500.csv', 50, True)\n",
    "X_train, y_train, X_test, y_test = lstm.load_data('m2.csv', 50, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compilation time :  0.06747198104858398\n"
     ]
    }
   ],
   "source": [
    "#Step 2 Build Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "    input_dim=1,\n",
    "    output_dim=50,\n",
    "    return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "    100,\n",
    "    return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# model.add(Dense(\n",
    "#     output_dim=256))\n",
    "# model.add(Activation('linear'))\n",
    "\n",
    "model.add(Dense(\n",
    "    output_dim=1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "start = time.time()\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "print( 'compilation time : ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3307 samples, validate on 175 samples\n",
      "Epoch 1/10\n",
      "3307/3307 [==============================] - 11s 3ms/step - loss: 0.3746 - val_loss: 0.3485\n",
      "Epoch 2/10\n",
      "3307/3307 [==============================] - 14s 4ms/step - loss: 0.3717 - val_loss: 0.3488\n",
      "Epoch 3/10\n",
      "3307/3307 [==============================] - 10s 3ms/step - loss: 0.3670 - val_loss: 0.3491\n",
      "Epoch 4/10\n",
      "3307/3307 [==============================] - 13s 4ms/step - loss: 0.3644 - val_loss: 0.3409\n",
      "Epoch 5/10\n",
      "3307/3307 [==============================] - 9s 3ms/step - loss: 0.3549 - val_loss: 0.3493\n",
      "Epoch 6/10\n",
      "3307/3307 [==============================] - 8s 2ms/step - loss: 0.3064 - val_loss: 0.2671\n",
      "Epoch 7/10\n",
      "1792/3307 [===============>..............] - ETA: 3s - loss: 0.2577"
     ]
    }
   ],
   "source": [
    "## Step 3 Train the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    nb_epoch=10,\n",
    "    validation_split=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Step 4 - Plot the predictions!\n",
    "predictions = predict_sequences_multiple(model, X_test, 50, 50)\n",
    "plot_results_multiple(predictions, y_test, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
